{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Handling :**\n",
        "In the following code blocks, we have read the h5 dataset (TVSum) and splitted it into train and test set."
      ],
      "metadata": {
        "id": "ce44bVqdtVEm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etC4wuOA3gl-"
      },
      "outputs": [],
      "source": [
        "# Importing essential libraries\n",
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow.keras as Keras\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKSqb2wClWM5"
      },
      "outputs": [],
      "source": [
        "# Mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i9Tyr4vV5G3E"
      },
      "outputs": [],
      "source": [
        "# Defining a Data Generator class to handle features of h5 file\n",
        "class DataGenerator(Keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self,dataset,batch_size=5,shuffle=False):\n",
        "      ''' Initialize the data'''\n",
        "\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "      ''' Returns length of the dataset'''\n",
        "\n",
        "        return int(np.floor(len(self.dataset)/self.batch_size))\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "      ''' Returns index, features and labels of the dataset'''\n",
        "\n",
        "        indexes = self.indices[index * self.batch_size : (index+1) * self.batch_size]\n",
        "        feature, label = self.__data_generation(indexes)\n",
        "\n",
        "        return feature, label\n",
        "\n",
        "    def __data_generation(self,indexes):\n",
        "      '''Returns features and labels'''\n",
        "\n",
        "        feature = np.empty((self.batch_size,320,1024))\n",
        "        label = np.empty((self.batch_size,320,1))\n",
        "\n",
        "        for i in range(len(indexes)):\n",
        "            feature[i,] = np.array(self.dataset[indexes[i]][0])\n",
        "            label[i,] = np.array(self.dataset[indexes[i]][1]).reshape(-1,1)\n",
        "\n",
        "        return feature,label\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "      '''Shuffles indices for epochs'''\n",
        "\n",
        "        self.indices = np.arange(len(self.dataset))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99n8lEJ_lW0D"
      },
      "outputs": [],
      "source": [
        "# Defining a class to read the h5 dataset\n",
        "class DatasetMaker(object):\n",
        "\n",
        "    def __init__(self,data_path):\n",
        "      '''Read file from defined path'''\n",
        "\n",
        "        self.data_file = h5py.File(data_path)\n",
        "\n",
        "    def __len__(self):\n",
        "      '''Returns length of the file'''\n",
        "\n",
        "        return len(self.data_file)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "      '''Returns feature, label and index of varoius keys'''\n",
        "\n",
        "        index += 1\n",
        "        video = self.data_file['video_'+str(index)]\n",
        "        feature = np.array(video['feature'][:])\n",
        "        label = np.array(video['label'][:])\n",
        "\n",
        "        return feature,label,index\n",
        "\n",
        "# Defining a function to read and split the dataset into train and test\n",
        "def get_loader(path, batch_size=5):\n",
        "  '''Takes file path as argument and returns train and test set'''\n",
        "\n",
        "    dataset = DatasetMaker(path)\n",
        "    train_dataset, test_dataset = train_test_split(dataset, test_size = 0.2)\n",
        "    train_loader = DataGenerator(train_dataset)\n",
        "\n",
        "    return train_loader, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo9kGpxns7kH"
      },
      "outputs": [],
      "source": [
        "# Getting train and test set\n",
        "train_loader, test_dataset=get_loader('/content/drive/MyDrive/suvidha internship/fcsn_tvsum.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5GBQfRTtZej",
        "outputId": "00d2dbd6-15bd-42f4-8a97-2f8016bd0be2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[[0.35250884, 0.35687858, 0.37622839, ..., 0.4116306 ,\n",
              "          0.37593332, 0.41581485],\n",
              "         [0.33224654, 0.381078  , 0.34691849, ..., 0.41855153,\n",
              "          0.40180525, 0.39628667],\n",
              "         [0.35970178, 0.37046221, 0.35555354, ..., 0.41693273,\n",
              "          0.40011674, 0.42686591],\n",
              "         ...,\n",
              "         [0.37487707, 0.3455686 , 0.3770965 , ..., 0.41539136,\n",
              "          0.39820242, 0.36128262],\n",
              "         [0.37143588, 0.35041133, 0.38537401, ..., 0.42188835,\n",
              "          0.41068125, 0.3635914 ],\n",
              "         [0.37933877, 0.35179704, 0.38787192, ..., 0.41555437,\n",
              "          0.40098241, 0.35158965]],\n",
              " \n",
              "        [[0.34310278, 0.32379588, 0.3629739 , ..., 0.41467142,\n",
              "          0.4268606 , 0.40030608],\n",
              "         [0.3324433 , 0.34779271, 0.33534241, ..., 0.41157749,\n",
              "          0.38300651, 0.40324458],\n",
              "         [0.34330019, 0.34221551, 0.31614497, ..., 0.41342187,\n",
              "          0.38614759, 0.41145793],\n",
              "         ...,\n",
              "         [0.36588389, 0.3762069 , 0.33913556, ..., 0.43120918,\n",
              "          0.3935608 , 0.39291403],\n",
              "         [0.36368343, 0.37608361, 0.34104207, ..., 0.43062326,\n",
              "          0.39569974, 0.39441267],\n",
              "         [0.36505976, 0.37688771, 0.33945647, ..., 0.43147948,\n",
              "          0.39247757, 0.39364573]],\n",
              " \n",
              "        [[0.32711574, 0.36090136, 0.35487548, ..., 0.43455762,\n",
              "          0.41222981, 0.40423819],\n",
              "         [0.35583112, 0.34358945, 0.38390523, ..., 0.42699414,\n",
              "          0.40920258, 0.40973708],\n",
              "         [0.33993497, 0.36056444, 0.35756734, ..., 0.41760808,\n",
              "          0.36041412, 0.39836091],\n",
              "         ...,\n",
              "         [0.36384341, 0.37387246, 0.39191553, ..., 0.42976627,\n",
              "          0.40843818, 0.39257786],\n",
              "         [0.35741773, 0.33870134, 0.3844749 , ..., 0.41993633,\n",
              "          0.37879801, 0.41165343],\n",
              "         [0.37617159, 0.34584692, 0.36718494, ..., 0.42151481,\n",
              "          0.40552357, 0.38530803]],\n",
              " \n",
              "        [[0.33176348, 0.35557672, 0.3468352 , ..., 0.422391  ,\n",
              "          0.38861853, 0.39562258],\n",
              "         [0.34116516, 0.34656888, 0.37913752, ..., 0.40323883,\n",
              "          0.41897646, 0.4018659 ],\n",
              "         [0.36368015, 0.35485679, 0.38723788, ..., 0.40327027,\n",
              "          0.39672229, 0.40829468],\n",
              "         ...,\n",
              "         [0.35148433, 0.36531976, 0.34404209, ..., 0.41290331,\n",
              "          0.37587854, 0.40423301],\n",
              "         [0.35487089, 0.33265963, 0.3563337 , ..., 0.42578998,\n",
              "          0.39450765, 0.39780959],\n",
              "         [0.35922298, 0.36004093, 0.36665532, ..., 0.43005067,\n",
              "          0.39202371, 0.38962358]],\n",
              " \n",
              "        [[0.34354067, 0.34820479, 0.34901711, ..., 0.4216471 ,\n",
              "          0.43304786, 0.36623067],\n",
              "         [0.3773436 , 0.39148268, 0.36803508, ..., 0.39389968,\n",
              "          0.36919096, 0.40827578],\n",
              "         [0.35909921, 0.38664407, 0.3538177 , ..., 0.43627825,\n",
              "          0.37309188, 0.39843258],\n",
              "         ...,\n",
              "         [0.34376672, 0.38123775, 0.37488726, ..., 0.41842332,\n",
              "          0.38172576, 0.38108653],\n",
              "         [0.35751432, 0.36326814, 0.38462582, ..., 0.39901546,\n",
              "          0.40823573, 0.40065083],\n",
              "         [0.36401126, 0.34983188, 0.3774398 , ..., 0.43043008,\n",
              "          0.4132655 , 0.40568045]]]), array([[[1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              " \n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              " \n",
              "        [[1.],\n",
              "         [1.],\n",
              "         [1.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              " \n",
              "        [[1.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.]],\n",
              " \n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]]))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting an overview of train set\n",
        "train_loader.__getitem__(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTeZubqDtbJf",
        "outputId": "ccdeac62-027f-4588-d140-9a9d134b1d74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0.319943  , 0.37948456, 0.32990432, ..., 0.43006426, 0.38723537,\n",
              "         0.43616933],\n",
              "        [0.32591122, 0.3689806 , 0.34779176, ..., 0.4292725 , 0.3834775 ,\n",
              "         0.4353265 ],\n",
              "        [0.32701132, 0.37345025, 0.344078  , ..., 0.43138295, 0.38321468,\n",
              "         0.43406087],\n",
              "        ...,\n",
              "        [0.3387942 , 0.36302942, 0.3892704 , ..., 0.41417256, 0.38435096,\n",
              "         0.39531755],\n",
              "        [0.35451224, 0.35858825, 0.35803077, ..., 0.44103327, 0.41493303,\n",
              "         0.4012603 ],\n",
              "        [0.3536804 , 0.3568709 , 0.35599893, ..., 0.44360656, 0.41518053,\n",
              "         0.3995843 ]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " 36)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Getting an overview of test set\n",
        "test_dataset[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training and Testing :**\n",
        "In this section, we have defined various functions to handle the algorithm in order and trained the model and tested it over the test set."
      ],
      "metadata": {
        "id": "3rQLUzmDwaYg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwmOSsfFtmiA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def knapsack(s, w, c): #shot, weights, capacity\n",
        "    ''' Takes Predicted value, Weights of shots and expected video length as input \n",
        "    and returns an array of chosen shot indices'''\n",
        "\n",
        "\n",
        "    shot = len(s) + 1 #number of shots\n",
        "    cap = c + 1 #capacity threshold\n",
        "\n",
        "    #matching the modified size by adding 0 at 0th index\n",
        "    s = np.r_[[0], s] #adding 0 at 0th index (concatinating)\n",
        "    w = np.r_[[0], w] #adding 0 at 0th index (concatinating)\n",
        "\n",
        "    #Creating and Filling Dynamic Programming Table with zeros in shot x cap dimensions\n",
        "    dp = [] #creating empty list or table\n",
        "    for j in range(shot):\n",
        "        dp.append([]) #s+1 rows\n",
        "        for i in range(cap):\n",
        "            dp[j].append(0) #c+1 columns\n",
        "\n",
        "    #Started filling values from (2nd row, 2nd column) till (shot X cap) and keeping the values for 0th indexes as 0\n",
        "    #following dynamic programming approach to fill values\n",
        "    for i in range(1,shot):\n",
        "        for j in range(1,cap):\n",
        "            if w[i] <= j:\n",
        "                dp[i][j] = max(s[i] + dp[i-1][j-w[i]], dp[i-1][j])\n",
        "            else:\n",
        "                dp[i][j] = dp[i-1][j]\n",
        "\n",
        "    #choosing the optimal pair of keyshots\n",
        "    choice = []\n",
        "    i = shot - 1\n",
        "    j = cap - 1\n",
        "    while i > 0 and j > 0:\n",
        "        if dp[i][j] != dp[i-1][j]: #starting from last element and going further\n",
        "            choice.append(i-1)\n",
        "            j = j - w[i]\n",
        "            i = i - 1\n",
        "        else:\n",
        "            i = i - 1\n",
        "\n",
        "    return dp[shot-1][cap-1], choice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_metrics(y_pred, y_true):\n",
        "  ''' Takes Predicted and True value as input and returns various evaluation metrics'''\n",
        "    overlap = np.sum(y_pred * y_true)\n",
        "    precision = overlap / (np.sum(y_pred) + 1e-8)\n",
        "    recall = overlap / (np.sum(y_true) + 1e-8)\n",
        "    if precision == 0 and recall == 0:\n",
        "        fscore = 0\n",
        "    else:\n",
        "        fscore = 2 * precision * recall / (precision + recall)\n",
        "    return [precision, recall, fscore]"
      ],
      "metadata": {
        "id": "XqXQj2hexaYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_keyshots(video_info, pred_score):\n",
        "  '''Takes Video Info and predicted score array as input and returns predicted score,\n",
        "  selected shots and predicted summary'''\n",
        "    vidlen = video_info['length'][()]\n",
        "    cps = video_info['change_points'][:]\n",
        "    weight = video_info['n_frame_per_seg'][:]\n",
        "    pred_score = np.array(pred_score)\n",
        "    pred_score = upsample(pred_score, vidlen)\n",
        "    pred_value = np.array([pred_score[cp[0]:cp[1]].mean() for cp in cps])\n",
        "    _, selected = knapsack(pred_value, weight, int(0.15 * vidlen))\n",
        "    selected = selected[::-1]\n",
        "    key_labels = np.zeros((vidlen,))\n",
        "    for i in selected:\n",
        "        key_labels[cps[i][0]:cps[i][1]] = 1\n",
        "    return pred_score.tolist(), selected, key_labels.tolist()"
      ],
      "metadata": {
        "id": "AcMzXO7jxvOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample(down_arr, vidlen):\n",
        "    up_arr = np.zeros(vidlen)\n",
        "    ratio = vidlen // 320\n",
        "    l = (vidlen - ratio * 320) // 2\n",
        "    i = 0\n",
        "    while i < 320:\n",
        "        up_arr[l:l+ratio] = np.ones(ratio, dtype = int) * down_arr[0][i]\n",
        "        l += ratio\n",
        "        i += 1\n",
        "    return up_arr"
      ],
      "metadata": {
        "id": "IJ2F_cwryaQy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Full_Stack_Code - V1.1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}